{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather-Prediction\n",
    "\n",
    "Predicting rain or weather is a common problem in machine learning. Different machine learning algorithms can be used to model and predict rainfall. In this assignment, we are asked to complete the analysis to predict whether there will be rain tomorrow or not. In particular, we are required to apply the tools of machine learning to visualize and predict the possibility of rainfall in Australia. \n",
    "\n",
    "We must make use of various Machine Learning Algorithms like **Decision Trees, Logistic Regression, Gradient Boosted Machines and Random Forest** to predict whether it will rain tomorrow or not. We shall make use of the various **functions and libraries** within pyspark itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Import Spark Session and Initialize Spark\n",
    "\n",
    "Let's begin with loading all the necessary modules in the system.\n",
    "\n",
    "- **SparkContext** and **SparkConf** from **pyspark** to create a **Spark Instance**\n",
    "\n",
    "- **SparkSession** from **pyspark.sql** to work with the **SparkSession**\n",
    "\n",
    "- **IntegerType and DoubleType** from **pyspark.sql.types** to convert datatypes\n",
    "\n",
    "- **mean, stddev, col and when** from **pyspark.sql.functions** for stats\n",
    "\n",
    "- **mode** from **statistics** to calculate the mode\n",
    "\n",
    "- **StringIndexer and VectorAssembler** from **pyspark.ml.feature** to perform one-hot encoding and making a feature vector\n",
    "\n",
    "- **LogisticRegression, DecisionTreeClassifier, RandomForestClassifier and GBTClassifier** from **pyspark.ml.classification** for Machine Learning Classifiers\n",
    "\n",
    "- **Pipeline** from **pyspark.ml** to sequence tasks one in an orderly way\n",
    "\n",
    "- **MulticlassClassificationEvaluator** from **pyspark.ml.evaluation** to evaluate Machine Learning model's performance\n",
    "\n",
    "- **MulticlassMetrics** from **pyspark.mllib.evaluation** to get the prediction performance of the model\n",
    "\n",
    "- **MLUtils** from **pyspark.mllib.util** to support MulticlassMetrics\n",
    "\n",
    "- **seaborn** for good visuaizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading relevant libraries\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import IntegerType, DoubleType\n",
    "from pyspark.sql.functions import mean as _mean, stddev as _stddev, col, when\n",
    "from statistics import mode as _mode\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, GBTClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.mllib.util import MLUtils\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to be creating a **Spark session** which will the configuration of our Spark **environment** and a **Spark Context** which will store this config.\n",
    "\n",
    "We shall now check if the `spark_context` has been created or not. If not, we will initialize the Spark session with our previously defined `spark_context` variable. We will be using only 4 cores for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_context = SparkContext.getOrCreate()\n",
    "\n",
    "# If there is no existing spark context, we now create a new context\n",
    "\n",
    "if (spark_context is None):\n",
    "    spark_context = SparkContext(master = \"local[4]\", appName = \"Assignment 2\")\n",
    "spark = SparkSession(sparkContext = spark_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Load the Dataset and Print the Schema and Total Number of Entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making use of the `spark.read.csv` function, we read in the weather data file. Let's store it in `rain_pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_pred = spark.read.csv('weatherAUS.csv', inferSchema = True, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display the first 10 rows of the dataset to get an idea about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------+-------+--------+-----------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+--------+--------+-------+-------+---------+------------+\n",
      "|      Date|Location|MinTemp|MaxTemp|Rainfall|Evaporation|Sunshine|WindGustDir|WindGustSpeed|WindDir9am|WindDir3pm|WindSpeed9am|WindSpeed3pm|Humidity9am|Humidity3pm|Pressure9am|Pressure3pm|Cloud9am|Cloud3pm|Temp9am|Temp3pm|RainToday|RainTomorrow|\n",
      "+----------+--------+-------+-------+--------+-----------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+--------+--------+-------+-------+---------+------------+\n",
      "|2008-12-01|  Albury|   13.4|   22.9|     0.6|         NA|      NA|          W|           44|         W|       WNW|          20|          24|         71|         22|     1007.7|     1007.1|       8|      NA|   16.9|   21.8|       No|          No|\n",
      "|2008-12-02|  Albury|    7.4|   25.1|       0|         NA|      NA|        WNW|           44|       NNW|       WSW|           4|          22|         44|         25|     1010.6|     1007.8|      NA|      NA|   17.2|   24.3|       No|          No|\n",
      "|2008-12-03|  Albury|   12.9|   25.7|       0|         NA|      NA|        WSW|           46|         W|       WSW|          19|          26|         38|         30|     1007.6|     1008.7|      NA|       2|     21|   23.2|       No|          No|\n",
      "|2008-12-04|  Albury|    9.2|     28|       0|         NA|      NA|         NE|           24|        SE|         E|          11|           9|         45|         16|     1017.6|     1012.8|      NA|      NA|   18.1|   26.5|       No|          No|\n",
      "|2008-12-05|  Albury|   17.5|   32.3|       1|         NA|      NA|          W|           41|       ENE|        NW|           7|          20|         82|         33|     1010.8|       1006|       7|       8|   17.8|   29.7|       No|          No|\n",
      "|2008-12-06|  Albury|   14.6|   29.7|     0.2|         NA|      NA|        WNW|           56|         W|         W|          19|          24|         55|         23|     1009.2|     1005.4|      NA|      NA|   20.6|   28.9|       No|          No|\n",
      "|2008-12-07|  Albury|   14.3|     25|       0|         NA|      NA|          W|           50|        SW|         W|          20|          24|         49|         19|     1009.6|     1008.2|       1|      NA|   18.1|   24.6|       No|          No|\n",
      "|2008-12-08|  Albury|    7.7|   26.7|       0|         NA|      NA|          W|           35|       SSE|         W|           6|          17|         48|         19|     1013.4|     1010.1|      NA|      NA|   16.3|   25.5|       No|          No|\n",
      "|2008-12-09|  Albury|    9.7|   31.9|       0|         NA|      NA|        NNW|           80|        SE|        NW|           7|          28|         42|          9|     1008.9|     1003.6|      NA|      NA|   18.3|   30.2|       No|         Yes|\n",
      "|2008-12-10|  Albury|   13.1|   30.1|     1.4|         NA|      NA|          W|           28|         S|       SSE|          15|          11|         58|         27|       1007|     1005.7|      NA|      NA|   20.1|   28.2|      Yes|          No|\n",
      "+----------+--------+-------+-------+--------+-----------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+--------+--------+-------+-------+---------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rain_pred.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm. Some of the columns contains a lot of NA's that must either be fixed or removed from our dataset. Printing the number of lines in the dataset, we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of lines in the Weather Australia is : 142193\n"
     ]
    }
   ],
   "source": [
    "print('Total number of lines in the Weather Australia is : ' + str(rain_pred.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Delete Columns from the Dataset  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, when there are many **NA values in a column**, the best option, keeping that we have a prediction task at hand, is to remove them. Keeping that particular column will only **negatively affect our prediction** and has to go. Therefore, as instructed in the specification, we are dropping the following columns :\n",
    "\n",
    "- Date\n",
    "- Location\n",
    "- Evaporation\n",
    "- Sunshine\n",
    "- Cloud9am\n",
    "- Cloud3pm\n",
    "- Temp9am\n",
    "- Temp3pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_pred = rain_pred.drop('Date', 'Location', 'Evaporation', 'Sunshine', 'Cloud9am', 'Cloud3pm', 'Temp9am', 'Temp3pm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect to see if they are really gone or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
      "|MinTemp|MaxTemp|Rainfall|WindGustDir|WindGustSpeed|WindDir9am|WindDir3pm|WindSpeed9am|WindSpeed3pm|Humidity9am|Humidity3pm|Pressure9am|Pressure3pm|RainToday|RainTomorrow|\n",
      "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
      "|   13.4|   22.9|     0.6|          W|           44|         W|       WNW|          20|          24|         71|         22|     1007.7|     1007.1|       No|          No|\n",
      "|    7.4|   25.1|       0|        WNW|           44|       NNW|       WSW|           4|          22|         44|         25|     1010.6|     1007.8|       No|          No|\n",
      "|   12.9|   25.7|       0|        WSW|           46|         W|       WSW|          19|          26|         38|         30|     1007.6|     1008.7|       No|          No|\n",
      "|    9.2|     28|       0|         NE|           24|        SE|         E|          11|           9|         45|         16|     1017.6|     1012.8|       No|          No|\n",
      "|   17.5|   32.3|       1|          W|           41|       ENE|        NW|           7|          20|         82|         33|     1010.8|       1006|       No|          No|\n",
      "|   14.6|   29.7|     0.2|        WNW|           56|         W|         W|          19|          24|         55|         23|     1009.2|     1005.4|       No|          No|\n",
      "|   14.3|     25|       0|          W|           50|        SW|         W|          20|          24|         49|         19|     1009.6|     1008.2|       No|          No|\n",
      "|    7.7|   26.7|       0|          W|           35|       SSE|         W|           6|          17|         48|         19|     1013.4|     1010.1|       No|          No|\n",
      "|    9.7|   31.9|       0|        NNW|           80|        SE|        NW|           7|          28|         42|          9|     1008.9|     1003.6|       No|         Yes|\n",
      "|   13.1|   30.1|     1.4|          W|           28|         S|       SSE|          15|          11|         58|         27|       1007|     1005.7|      Yes|          No|\n",
      "|   13.4|   30.4|       0|          N|           30|       SSE|       ESE|          17|           6|         48|         22|     1011.8|     1008.7|       No|         Yes|\n",
      "|   15.9|   21.7|     2.2|        NNE|           31|        NE|       ENE|          15|          13|         89|         91|     1010.5|     1004.2|      Yes|         Yes|\n",
      "|   15.9|   18.6|    15.6|          W|           61|       NNW|       NNW|          28|          28|         76|         93|      994.3|        993|      Yes|         Yes|\n",
      "|   12.6|     21|     3.6|         SW|           44|         W|       SSW|          24|          20|         65|         43|     1001.2|     1001.8|      Yes|          No|\n",
      "|    9.8|   27.7|      NA|        WNW|           50|        NA|       WNW|          NA|          22|         50|         28|     1013.4|     1010.3|       NA|          No|\n",
      "|   14.1|   20.9|       0|        ENE|           22|       SSW|         E|          11|           9|         69|         82|     1012.2|     1010.4|       No|         Yes|\n",
      "|   13.5|   22.9|    16.8|          W|           63|         N|       WNW|           6|          20|         80|         65|     1005.8|     1002.2|      Yes|         Yes|\n",
      "|   11.2|   22.5|    10.6|        SSE|           43|       WSW|        SW|          24|          17|         47|         32|     1009.4|     1009.7|      Yes|          No|\n",
      "|    9.8|   25.6|       0|        SSE|           26|        SE|       NNW|          17|           6|         45|         26|     1019.2|     1017.1|       No|          No|\n",
      "|   11.5|   29.3|       0|          S|           24|        SE|        SE|           9|           9|         56|         28|     1019.3|     1014.8|       No|          No|\n",
      "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rain_pred.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MinTemp',\n",
       " 'MaxTemp',\n",
       " 'Rainfall',\n",
       " 'WindGustDir',\n",
       " 'WindGustSpeed',\n",
       " 'WindDir9am',\n",
       " 'WindDir3pm',\n",
       " 'WindSpeed9am',\n",
       " 'WindSpeed3pm',\n",
       " 'Humidity9am',\n",
       " 'Humidity3pm',\n",
       " 'Pressure9am',\n",
       " 'Pressure3pm',\n",
       " 'RainToday',\n",
       " 'RainTomorrow']"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rain_pred.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We have only retained the columns that will be useful to us for making predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 - Print the Number of Missing Data in each Column\n",
    "\n",
    "In this task, we must display the number of **null values in each column**. As this is something that we will be using on multiple ocassions in our assignment, it only makes sense to make a function, we will call it `missing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing():\n",
    "    \n",
    "    for columns in rain_pred.columns:\n",
    "        print(columns + ' has number of NULLs : ' + str(rain_pred[rain_pred[columns] == 'NA'].count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinTemp has number of NULLs : 637\n",
      "MaxTemp has number of NULLs : 322\n",
      "Rainfall has number of NULLs : 1406\n",
      "WindGustDir has number of NULLs : 9330\n",
      "WindGustSpeed has number of NULLs : 9270\n",
      "WindDir9am has number of NULLs : 10013\n",
      "WindDir3pm has number of NULLs : 3778\n",
      "WindSpeed9am has number of NULLs : 1348\n",
      "WindSpeed3pm has number of NULLs : 2630\n",
      "Humidity9am has number of NULLs : 1774\n",
      "Humidity3pm has number of NULLs : 3610\n",
      "Pressure9am has number of NULLs : 14014\n",
      "Pressure3pm has number of NULLs : 13981\n",
      "RainToday has number of NULLs : 1406\n",
      "RainTomorrow has number of NULLs : 0\n"
     ]
    }
   ],
   "source": [
    "missing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at that! We have the count of all the Null values in our dataset. We can now think about how we want to fix them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 - Fill the Missing Data with Average Value and Maximum Occurrence  Value\n",
    "\n",
    "Here, we are asked to fill the missing values in our dataset. It's simple, if it's a **numerical column**, then we simply replace it with the **average of that column**. If it's a **categorical column**, we replace it by the **maximum frequency value**.\n",
    "\n",
    "For this task, let's run a loop over all the columns in our dataset to see their datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The datatype of MinTemp <class 'str'>\n",
      "The datatype of MaxTemp <class 'str'>\n",
      "The datatype of Rainfall <class 'str'>\n",
      "The datatype of WindGustDir <class 'str'>\n",
      "The datatype of WindGustSpeed <class 'str'>\n",
      "The datatype of WindDir9am <class 'str'>\n",
      "The datatype of WindDir3pm <class 'str'>\n",
      "The datatype of WindSpeed9am <class 'str'>\n",
      "The datatype of WindSpeed3pm <class 'str'>\n",
      "The datatype of Humidity9am <class 'str'>\n",
      "The datatype of Humidity3pm <class 'str'>\n",
      "The datatype of Pressure9am <class 'str'>\n",
      "The datatype of Pressure3pm <class 'str'>\n",
      "The datatype of RainToday <class 'str'>\n",
      "The datatype of RainTomorrow <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for columns in rain_pred.columns:\n",
    "    \n",
    "    print('The datatype of ' + str(columns) + ' ' + str(type(columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is string! Not very helpful, is it? Let's try and calculate the **average** of each column anyway. If it turns out to be a number then we know that column is **numeric**, otherwise it's **categorical**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(avg(MinTemp)=12.186399728729294)]\n",
      "[Row(avg(MaxTemp)=23.226784191272504)]\n",
      "[Row(avg(Rainfall)=2.3499740743107256)]\n",
      "[Row(avg(WindGustDir)=None)]\n",
      "[Row(avg(WindGustSpeed)=39.98429165757619)]\n",
      "[Row(avg(WindDir9am)=None)]\n",
      "[Row(avg(WindDir3pm)=None)]\n",
      "[Row(avg(WindSpeed9am)=14.001988000994)]\n",
      "[Row(avg(WindSpeed3pm)=18.63757586179718)]\n",
      "[Row(avg(Humidity9am)=68.8438103105705)]\n",
      "[Row(avg(Humidity3pm)=51.482606091656265)]\n",
      "[Row(avg(Pressure9am)=1017.6537584159605)]\n",
      "[Row(avg(Pressure3pm)=1015.2582035378871)]\n",
      "[Row(avg(RainToday)=None)]\n",
      "[Row(avg(RainTomorrow)=None)]\n"
     ]
    }
   ],
   "source": [
    "for columns in rain_pred.columns:\n",
    "    print(rain_pred.select(_mean(col(columns))).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There you go! We have the following columns as **numeric** : \n",
    "\n",
    "- MinTemp\n",
    "- MaxTemp\n",
    "- Rainfall\n",
    "- WindGustSpeed\n",
    "- WindSpeed9am\n",
    "- WindSpeed3pm\n",
    "- Humidity9am\n",
    "- Humidity3pm\n",
    "- Pressure9am\n",
    "- Pressure3pm\n",
    "\n",
    "And the rest are **categorical**, namely :\n",
    "\n",
    "- WindGustDir\n",
    "- WindDir9am\n",
    "- WindDir3pm\n",
    "- RainToday\n",
    "- RainTomorrow\n",
    "\n",
    "We will have to have different strategies for these two types. Let's get right into it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Numerical Columns\n",
    "\n",
    "We're gonna first find the average of that column and then use that to replace it with the NA's in that column. We shall be making use of the `.describe()`, `.collect()`, `.select()`, `.withColumn()`, `when()` and `otherwise()` methods, in a chained format for replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MinTemp_mean = rain_pred.select('MinTemp').describe().collect()[1][1]\n",
    "rain_pred = rain_pred.withColumn('MinTemp', when(rain_pred['MinTemp'] == 'NA', MinTemp_mean).\n",
    "                                                                     otherwise(rain_pred['MinTemp']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MaxTemp_mean = rain_pred.select('MaxTemp').describe().collect()[1][1]\n",
    "rain_pred = rain_pred.withColumn('MaxTemp', when(rain_pred['MaxTemp'] == 'NA', MaxTemp_mean).\n",
    "                                                                     otherwise(rain_pred['MaxTemp']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rainfall_mean = rain_pred.select('Rainfall').describe().collect()[1][1]\n",
    "rain_pred = rain_pred.withColumn('Rainfall', when(rain_pred['Rainfall'] == 'NA', Rainfall_mean).\n",
    "                                                                     otherwise(rain_pred['Rainfall']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WindGustSpeed_mean = rain_pred.select('WindGustSpeed').describe().collect()[1][1]\n",
    "rain_pred = rain_pred.withColumn('WindGustSpeed', when(rain_pred['WindGustSpeed'] == 'NA', WindGustSpeed_mean).\n",
    "                                                                     otherwise(rain_pred['WindGustSpeed']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WindSpeed9am_mean = rain_pred.select('WindSpeed9am').describe().collect()[1][1]\n",
    "rain_pred = rain_pred.withColumn('WindSpeed9am', when(rain_pred['WindSpeed9am'] == 'NA', WindSpeed9am_mean).\n",
    "                                                                     otherwise(rain_pred['WindSpeed9am']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WindSpeed3pm_mean = rain_pred.select('WindSpeed3pm').describe().collect()[1][1]\n",
    "rain_pred = rain_pred.withColumn('WindSpeed3pm', when(rain_pred['WindSpeed3pm'] == 'NA', WindSpeed3pm_mean).\n",
    "                                                                     otherwise(rain_pred['WindSpeed3pm']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Humidity9am_mean = rain_pred.select('Humidity9am').describe().collect()[1][1]\n",
    "rain_pred = rain_pred.withColumn('Humidity9am', when(rain_pred['Humidity9am'] == 'NA', Humidity9am_mean).\n",
    "                                                                     otherwise(rain_pred['Humidity9am']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Humidity3pm_mean = rain_pred.select('Humidity3pm').describe().collect()[1][1]\n",
    "rain_pred = rain_pred.withColumn('Humidity3pm', when(rain_pred['Humidity3pm'] == 'NA', Humidity3pm_mean).\n",
    "                                                                     otherwise(rain_pred['Humidity3pm']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pressure9am_mean = rain_pred.select('Pressure9am').describe().collect()[1][1]\n",
    "rain_pred = rain_pred.withColumn('Pressure9am', when(rain_pred['Pressure9am'] == 'NA', Pressure9am_mean).\n",
    "                                                                     otherwise(rain_pred['Pressure9am']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pressure3pm_mean = rain_pred.select('Pressure3pm').describe().collect()[1][1]\n",
    "rain_pred = rain_pred.withColumn('Pressure3pm', when(rain_pred['Pressure3pm'] == 'NA', Pressure3pm_mean).\n",
    "                                                                     otherwise(rain_pred['Pressure3pm']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phew! That was a lot of code! Let's check if it even worked or not. We will call the `missing()` again, which we made earlier. Isn't is good to have such a function in handy, instead of writing the code again and again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinTemp has number of NULLs : 0\n",
      "MaxTemp has number of NULLs : 0\n",
      "Rainfall has number of NULLs : 0\n",
      "WindGustDir has number of NULLs : 9330\n",
      "WindGustSpeed has number of NULLs : 0\n",
      "WindDir9am has number of NULLs : 10013\n",
      "WindDir3pm has number of NULLs : 3778\n",
      "WindSpeed9am has number of NULLs : 0\n",
      "WindSpeed3pm has number of NULLs : 0\n",
      "Humidity9am has number of NULLs : 0\n",
      "Humidity3pm has number of NULLs : 0\n",
      "Pressure9am has number of NULLs : 0\n",
      "Pressure3pm has number of NULLs : 0\n",
      "RainToday has number of NULLs : 1406\n",
      "RainTomorrow has number of NULLs : 0\n"
     ]
    }
   ],
   "source": [
    "missing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazing! **No Null values** in the **numerical columns**! Moving on to the **categorical columns**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Categorical Columns\n",
    "\n",
    "Things will be a bit different here, we shall make use of the `.groupBy()`, `.count()`, `orderBy()` and `.sort()` methods on our dataset to firstly see, and then change their values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|WindGustDir|count|\n",
      "+-----------+-----+\n",
      "|          W| 9780|\n",
      "|         NA| 9330|\n",
      "|         SE| 9309|\n",
      "|          E| 9071|\n",
      "|          N| 9033|\n",
      "|        SSE| 8993|\n",
      "|          S| 8949|\n",
      "|        WSW| 8901|\n",
      "|         SW| 8797|\n",
      "|        SSW| 8610|\n",
      "|        WNW| 8066|\n",
      "|         NW| 8003|\n",
      "|        ENE| 7992|\n",
      "|        ESE| 7305|\n",
      "|         NE| 7060|\n",
      "|        NNW| 6561|\n",
      "|        NNE| 6433|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rain_pred.groupBy('WindGustDir').count().orderBy('WindGustDir').sort('count', ascending = False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|WindDir9am|count|\n",
      "+----------+-----+\n",
      "|         N|11393|\n",
      "|        NA|10013|\n",
      "|        SE| 9162|\n",
      "|         E| 9024|\n",
      "|       SSE| 8966|\n",
      "|        NW| 8552|\n",
      "|         S| 8493|\n",
      "|         W| 8260|\n",
      "|        SW| 8237|\n",
      "|       NNE| 7948|\n",
      "|       NNW| 7840|\n",
      "|       ENE| 7735|\n",
      "|       ESE| 7558|\n",
      "|        NE| 7527|\n",
      "|       SSW| 7448|\n",
      "|       WNW| 7194|\n",
      "|       WSW| 6843|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rain_pred.groupBy('WindDir9am').count().orderBy('WindDir9am').sort('count', ascending = False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|WindDir3pm|count|\n",
      "+----------+-----+\n",
      "|        SE|10663|\n",
      "|         W| 9911|\n",
      "|         S| 9598|\n",
      "|       WSW| 9329|\n",
      "|        SW| 9182|\n",
      "|       SSE| 9142|\n",
      "|         N| 8667|\n",
      "|       WNW| 8656|\n",
      "|        NW| 8468|\n",
      "|       ESE| 8382|\n",
      "|         E| 8342|\n",
      "|        NE| 8164|\n",
      "|       SSW| 8010|\n",
      "|       NNW| 7733|\n",
      "|       ENE| 7724|\n",
      "|       NNE| 6444|\n",
      "|        NA| 3778|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rain_pred.groupBy('WindDir3pm').count().orderBy('WindDir3pm').sort('count', ascending = False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|RainToday| count|\n",
      "+---------+------+\n",
      "|       No|109332|\n",
      "|      Yes| 31455|\n",
      "|       NA|  1406|\n",
      "+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rain_pred.groupBy('RainToday').count().orderBy('RainToday').sort('count', ascending = False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things will be a bit different here, we shall make use of the `.groupBy()`, `.count()`, `orderBy()` and `.sort()` methods on our dataset to firstly see, and then change their values in the dataset.\n",
    "\n",
    "Let's store the top value in a variable and print it out to see if it's actually the correct value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'W'"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WindGustDir_mode = rain_pred.groupBy('WindGustDir').count().orderBy('WindGustDir').sort('count', ascending = False).collect()[0][0]\n",
    "WindGustDir_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'N'"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WindDir9am_mode = rain_pred.groupBy('WindDir9am').count().orderBy('WindDir9am').sort('count', ascending = False).collect()[0][0]\n",
    "WindDir9am_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SE'"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WindDir3pm_mode = rain_pred.groupBy('WindDir3pm').count().orderBy('WindDir3pm').sort('count', ascending = False).collect()[0][0]\n",
    "WindDir3pm_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No'"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RainToday_mode = rain_pred.groupBy('RainToday').count().orderBy('RainToday').sort('count', ascending = False).collect()[0][0]\n",
    "RainToday_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of them work! Now let's use a similar syntaxt to replace the actual null values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_pred = rain_pred.withColumn('WindGustDir', when(rain_pred['WindGustDir'] == 'NA', WindGustDir_mode).\n",
    "                                                                     otherwise(rain_pred['WindGustDir']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_pred = rain_pred.withColumn('WindDir9am', when(rain_pred['WindDir9am'] == 'NA', WindDir9am_mode).\n",
    "                                                                     otherwise(rain_pred['WindDir9am']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_pred = rain_pred.withColumn('WindDir3pm', when(rain_pred['WindDir3pm'] == 'NA', WindDir3pm_mode).\n",
    "                                                                     otherwise(rain_pred['WindDir3pm']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_pred = rain_pred.withColumn('RainToday', when(rain_pred['RainToday'] == 'NA', RainToday_mode).\n",
    "                                                                     otherwise(rain_pred['RainToday']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, let's call our great friend, the `missing()` to get the number of nulls in the dataset. Remember that all the numerical columns were without nulls in the starting of this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinTemp has number of NULLs : 0\n",
      "MaxTemp has number of NULLs : 0\n",
      "Rainfall has number of NULLs : 0\n",
      "WindGustDir has number of NULLs : 0\n",
      "WindGustSpeed has number of NULLs : 0\n",
      "WindDir9am has number of NULLs : 0\n",
      "WindDir3pm has number of NULLs : 0\n",
      "WindSpeed9am has number of NULLs : 0\n",
      "WindSpeed3pm has number of NULLs : 0\n",
      "Humidity9am has number of NULLs : 0\n",
      "Humidity3pm has number of NULLs : 0\n",
      "Pressure9am has number of NULLs : 0\n",
      "Pressure3pm has number of NULLs : 0\n",
      "RainToday has number of NULLs : 0\n",
      "RainTomorrow has number of NULLs : 0\n"
     ]
    }
   ],
   "source": [
    "missing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic! All nulls are gone! We can now move on to some basic datatype transformations which we can directly feed into the Machine Learning algorithms and watch the magic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 - Data Transformation\n",
    "\n",
    "Machine Learning Algorithms, often except only **numerical columns** as input and would throw an error if supplied with **categorical** variables. Hence, we need to convert the numerical columns from **string** to **double** and convert categorical columns from **string** to **numbers** that the algorithm can directly use to process.\n",
    "\n",
    "First, let's make a list of numerical columns and name it `numerical_list`. Looping over the numerical_list, we use `cast(DoubleType())` to convert it from **string** to **double**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_list = ['MinTemp', 'MaxTemp', 'Rainfall', 'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am',\n",
    "                  'Humidity3pm', 'Pressure9am', 'Pressure3pm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for columns in numerical_list:\n",
    "    rain_pred = rain_pred.withColumn(columns, rain_pred[columns].cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect if it changed or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- MinTemp: double (nullable = true)\n",
      " |-- MaxTemp: double (nullable = true)\n",
      " |-- Rainfall: double (nullable = true)\n",
      " |-- WindGustDir: string (nullable = true)\n",
      " |-- WindGustSpeed: double (nullable = true)\n",
      " |-- WindDir9am: string (nullable = true)\n",
      " |-- WindDir3pm: string (nullable = true)\n",
      " |-- WindSpeed9am: double (nullable = true)\n",
      " |-- WindSpeed3pm: double (nullable = true)\n",
      " |-- Humidity9am: double (nullable = true)\n",
      " |-- Humidity3pm: double (nullable = true)\n",
      " |-- Pressure9am: double (nullable = true)\n",
      " |-- Pressure3pm: double (nullable = true)\n",
      " |-- RainToday: string (nullable = true)\n",
      " |-- RainTomorrow: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rain_pred.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, for categorical columns, we make a list named `categorical_list`, loop over it and use the `StringIndexer()` method, call the `Pipeline()` method on it and finally use the `.fit()` to fit it to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_list = ['WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday', 'RainTomorrow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+-----------------+----------------+----------------+---------------+------------------+\n",
      "|MinTemp|MaxTemp|Rainfall|WindGustDir|WindGustSpeed|WindDir9am|WindDir3pm|WindSpeed9am|WindSpeed3pm|Humidity9am|Humidity3pm|Pressure9am|Pressure3pm|RainToday|RainTomorrow|WindGustDir_index|WindDir9am_index|WindDir3pm_index|RainToday_index|RainTomorrow_index|\n",
      "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+-----------------+----------------+----------------+---------------+------------------+\n",
      "|   13.4|   22.9|     0.6|          W|         44.0|         W|       WNW|        20.0|        24.0|       71.0|       22.0|     1007.7|     1007.1|       No|          No|              0.0|             6.0|             7.0|            0.0|               0.0|\n",
      "|    7.4|   25.1|     0.0|        WNW|         44.0|       NNW|       WSW|         4.0|        22.0|       44.0|       25.0|     1010.6|     1007.8|       No|          No|              9.0|             9.0|             3.0|            0.0|               0.0|\n",
      "|   12.9|   25.7|     0.0|        WSW|         46.0|         W|       WSW|        19.0|        26.0|       38.0|       30.0|     1007.6|     1008.7|       No|          No|              6.0|             6.0|             3.0|            0.0|               0.0|\n",
      "|    9.2|   28.0|     0.0|         NE|         24.0|        SE|         E|        11.0|         9.0|       45.0|       16.0|     1017.6|     1012.8|       No|          No|             13.0|             1.0|            10.0|            0.0|               0.0|\n",
      "|   17.5|   32.3|     1.0|          W|         41.0|       ENE|        NW|         7.0|        20.0|       82.0|       33.0|     1010.8|     1006.0|       No|          No|              0.0|            10.0|             8.0|            0.0|               0.0|\n",
      "|   14.6|   29.7|     0.2|        WNW|         56.0|         W|         W|        19.0|        24.0|       55.0|       23.0|     1009.2|     1005.4|       No|          No|              9.0|             6.0|             1.0|            0.0|               0.0|\n",
      "|   14.3|   25.0|     0.0|          W|         50.0|        SW|         W|        20.0|        24.0|       49.0|       19.0|     1009.6|     1008.2|       No|          No|              0.0|             7.0|             1.0|            0.0|               0.0|\n",
      "|    7.7|   26.7|     0.0|          W|         35.0|       SSE|         W|         6.0|        17.0|       48.0|       19.0|     1013.4|     1010.1|       No|          No|              0.0|             3.0|             1.0|            0.0|               0.0|\n",
      "|    9.7|   31.9|     0.0|        NNW|         80.0|        SE|        NW|         7.0|        28.0|       42.0|        9.0|     1008.9|     1003.6|       No|         Yes|             14.0|             1.0|             8.0|            0.0|               1.0|\n",
      "|   13.1|   30.1|     1.4|          W|         28.0|         S|       SSE|        15.0|        11.0|       58.0|       27.0|     1007.0|     1005.7|      Yes|          No|              0.0|             5.0|             5.0|            1.0|               0.0|\n",
      "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+-----------------+----------------+----------------+---------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexers = [StringIndexer(inputCol = column, outputCol = column + \"_index\").fit(rain_pred) for column in categorical_list]\n",
    "\n",
    "\n",
    "pipeline = Pipeline(stages = indexers)\n",
    "rain_pred_indexers = pipeline.fit(rain_pred).transform(rain_pred)\n",
    "\n",
    "rain_pred_indexers.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see how the categories have been changed to numbers rather than string? But there is one more problem. We have new columns with `_index` suffix along with their old counterparts which contain the **string** categories as well. We have to drop them from our dataset. We can do this using the `.drop()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+-------------+------------+------------+-----------+-----------+-----------+-----------+-----------------+----------------+----------------+---------------+------------------+\n",
      "|MinTemp|MaxTemp|Rainfall|WindGustSpeed|WindSpeed9am|WindSpeed3pm|Humidity9am|Humidity3pm|Pressure9am|Pressure3pm|WindGustDir_index|WindDir9am_index|WindDir3pm_index|RainToday_index|RainTomorrow_index|\n",
      "+-------+-------+--------+-------------+------------+------------+-----------+-----------+-----------+-----------+-----------------+----------------+----------------+---------------+------------------+\n",
      "|   13.4|   22.9|     0.6|         44.0|        20.0|        24.0|       71.0|       22.0|     1007.7|     1007.1|              0.0|             6.0|             7.0|            0.0|               0.0|\n",
      "|    7.4|   25.1|     0.0|         44.0|         4.0|        22.0|       44.0|       25.0|     1010.6|     1007.8|              9.0|             9.0|             3.0|            0.0|               0.0|\n",
      "|   12.9|   25.7|     0.0|         46.0|        19.0|        26.0|       38.0|       30.0|     1007.6|     1008.7|              6.0|             6.0|             3.0|            0.0|               0.0|\n",
      "|    9.2|   28.0|     0.0|         24.0|        11.0|         9.0|       45.0|       16.0|     1017.6|     1012.8|             13.0|             1.0|            10.0|            0.0|               0.0|\n",
      "|   17.5|   32.3|     1.0|         41.0|         7.0|        20.0|       82.0|       33.0|     1010.8|     1006.0|              0.0|            10.0|             8.0|            0.0|               0.0|\n",
      "|   14.6|   29.7|     0.2|         56.0|        19.0|        24.0|       55.0|       23.0|     1009.2|     1005.4|              9.0|             6.0|             1.0|            0.0|               0.0|\n",
      "|   14.3|   25.0|     0.0|         50.0|        20.0|        24.0|       49.0|       19.0|     1009.6|     1008.2|              0.0|             7.0|             1.0|            0.0|               0.0|\n",
      "|    7.7|   26.7|     0.0|         35.0|         6.0|        17.0|       48.0|       19.0|     1013.4|     1010.1|              0.0|             3.0|             1.0|            0.0|               0.0|\n",
      "|    9.7|   31.9|     0.0|         80.0|         7.0|        28.0|       42.0|        9.0|     1008.9|     1003.6|             14.0|             1.0|             8.0|            0.0|               1.0|\n",
      "|   13.1|   30.1|     1.4|         28.0|        15.0|        11.0|       58.0|       27.0|     1007.0|     1005.7|              0.0|             5.0|             5.0|            1.0|               0.0|\n",
      "+-------+-------+--------+-------------+------------+------------+-----------+-----------+-----------+-----------+-----------------+----------------+----------------+---------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drop = ['WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday', 'RainTomorrow']\n",
    "\n",
    "rain_pred_indexers = rain_pred_indexers.drop(*drop)\n",
    "\n",
    "rain_pred_indexers.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Onto the next step!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7 - Create the Feature Vector and Divide the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are required to use the `VectorAssembler()` to convert the set of features into a **feature vector**. It can be easily done using the following piece of code which has been taken from a StackOverflow code snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['RainTomorrow_index']\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols = [columns for columns in rain_pred_indexers.columns if columns not in target],\n",
    "    outputCol = 'feature_vector')\n",
    "\n",
    "rain_pred_indexers_data = assembler.transform(rain_pred_indexers) # converting the whole row to a vector except\n",
    "                                                                  # the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+-------------+------------+------------+-----------+-----------+-----------+-----------+-----------------+----------------+----------------+---------------+------------------+--------------------+\n",
      "|MinTemp|MaxTemp|Rainfall|WindGustSpeed|WindSpeed9am|WindSpeed3pm|Humidity9am|Humidity3pm|Pressure9am|Pressure3pm|WindGustDir_index|WindDir9am_index|WindDir3pm_index|RainToday_index|RainTomorrow_index|      feature_vector|\n",
      "+-------+-------+--------+-------------+------------+------------+-----------+-----------+-----------+-----------+-----------------+----------------+----------------+---------------+------------------+--------------------+\n",
      "|   13.4|   22.9|     0.6|         44.0|        20.0|        24.0|       71.0|       22.0|     1007.7|     1007.1|              0.0|             6.0|             7.0|            0.0|               0.0|[13.4,22.9,0.6,44...|\n",
      "|    7.4|   25.1|     0.0|         44.0|         4.0|        22.0|       44.0|       25.0|     1010.6|     1007.8|              9.0|             9.0|             3.0|            0.0|               0.0|[7.4,25.1,0.0,44....|\n",
      "|   12.9|   25.7|     0.0|         46.0|        19.0|        26.0|       38.0|       30.0|     1007.6|     1008.7|              6.0|             6.0|             3.0|            0.0|               0.0|[12.9,25.7,0.0,46...|\n",
      "|    9.2|   28.0|     0.0|         24.0|        11.0|         9.0|       45.0|       16.0|     1017.6|     1012.8|             13.0|             1.0|            10.0|            0.0|               0.0|[9.2,28.0,0.0,24....|\n",
      "|   17.5|   32.3|     1.0|         41.0|         7.0|        20.0|       82.0|       33.0|     1010.8|     1006.0|              0.0|            10.0|             8.0|            0.0|               0.0|[17.5,32.3,1.0,41...|\n",
      "|   14.6|   29.7|     0.2|         56.0|        19.0|        24.0|       55.0|       23.0|     1009.2|     1005.4|              9.0|             6.0|             1.0|            0.0|               0.0|[14.6,29.7,0.2,56...|\n",
      "|   14.3|   25.0|     0.0|         50.0|        20.0|        24.0|       49.0|       19.0|     1009.6|     1008.2|              0.0|             7.0|             1.0|            0.0|               0.0|[14.3,25.0,0.0,50...|\n",
      "|    7.7|   26.7|     0.0|         35.0|         6.0|        17.0|       48.0|       19.0|     1013.4|     1010.1|              0.0|             3.0|             1.0|            0.0|               0.0|[7.7,26.7,0.0,35....|\n",
      "|    9.7|   31.9|     0.0|         80.0|         7.0|        28.0|       42.0|        9.0|     1008.9|     1003.6|             14.0|             1.0|             8.0|            0.0|               1.0|[9.7,31.9,0.0,80....|\n",
      "|   13.1|   30.1|     1.4|         28.0|        15.0|        11.0|       58.0|       27.0|     1007.0|     1005.7|              0.0|             5.0|             5.0|            1.0|               0.0|[13.1,30.1,1.4,28...|\n",
      "+-------+-------+--------+-------------+------------+------------+-----------+-----------+-----------+-----------+-----------------+----------------+----------------+---------------+------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rain_pred_indexers_data.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the feature vector in the middle? Yes, that's the one.\n",
    "\n",
    "Now we have everything we need to train our model and get predictions. Let's split our data into training and test set with 70:30 ratio respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_test, rain_train = rain_pred_indexers_data.randomSplit([0.3, 0.7], seed = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43043"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rain_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99150"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rain_train.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8 - Apply Machine Learning Classification Algorithms on the Dataset and Compare their Accuracy. Plot the Accuracy as Bar Graph\n",
    "\n",
    "Alas! Were at the most interesting stage of the assignment, building machine learning algorithms!\n",
    "\n",
    "We shall start with Decision Trees. Using the `DecisionTreeClassifier()` and `.fit()` method on our training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_Classifier = DecisionTreeClassifier(labelCol = 'RainTomorrow_index', featuresCol = 'feature_vector')\n",
    "DT_Model = DT_Classifier.fit(rain_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the `.transform()` on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_Prediction = DT_Model.transform(rain_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print out the predictions that our model made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(MinTemp=-3.3, MaxTemp=22.2, Rainfall=0.0, WindGustSpeed=30.0, WindSpeed9am=0.0, WindSpeed3pm=13.0, Humidity9am=90.0, Humidity3pm=24.0, Pressure9am=1021.7, Pressure3pm=1016.2, WindGustDir_index=0.0, WindDir9am_index=0.0, WindDir3pm_index=7.0, RainToday_index=0.0, RainTomorrow_index=0.0, feature_vector=DenseVector([-3.3, 22.2, 0.0, 30.0, 0.0, 13.0, 90.0, 24.0, 1021.7, 1016.2, 0.0, 0.0, 7.0, 0.0]), rawPrediction=DenseVector([43617.0, 3814.0]), probability=DenseVector([0.9196, 0.0804]), prediction=0.0),\n",
       " Row(MinTemp=-3.1, MaxTemp=12.4, Rainfall=0.0, WindGustSpeed=13.0, WindSpeed9am=6.0, WindSpeed3pm=2.0, Humidity9am=69.0, Humidity3pm=60.0, Pressure9am=1029.2, Pressure3pm=1027.3, WindGustDir_index=13.0, WindDir9am_index=12.0, WindDir3pm_index=3.0, RainToday_index=0.0, RainTomorrow_index=0.0, feature_vector=DenseVector([-3.1, 12.4, 0.0, 13.0, 6.0, 2.0, 69.0, 60.0, 1029.2, 1027.3, 13.0, 12.0, 3.0, 0.0]), rawPrediction=DenseVector([24284.0, 5814.0]), probability=DenseVector([0.8068, 0.1932]), prediction=0.0),\n",
       " Row(MinTemp=-3.0, MaxTemp=13.3, Rainfall=0.0, WindGustSpeed=26.0, WindSpeed9am=7.0, WindSpeed3pm=13.0, Humidity9am=74.0, Humidity3pm=46.0, Pressure9am=1035.2, Pressure3pm=1032.6, WindGustDir_index=7.0, WindDir9am_index=10.0, WindDir3pm_index=4.0, RainToday_index=0.0, RainTomorrow_index=0.0, feature_vector=DenseVector([-3.0, 13.3, 0.0, 26.0, 7.0, 13.0, 74.0, 46.0, 1035.2, 1032.6, 7.0, 10.0, 4.0, 0.0]), rawPrediction=DenseVector([43617.0, 3814.0]), probability=DenseVector([0.9196, 0.0804]), prediction=0.0),\n",
       " Row(MinTemp=-3.0, MaxTemp=15.4, Rainfall=0.6, WindGustSpeed=24.0, WindSpeed9am=7.0, WindSpeed3pm=11.0, Humidity9am=81.0, Humidity3pm=34.0, Pressure9am=1025.3, Pressure3pm=1022.5, WindGustDir_index=5.0, WindDir9am_index=10.0, WindDir3pm_index=1.0, RainToday_index=0.0, RainTomorrow_index=0.0, feature_vector=DenseVector([-3.0, 15.4, 0.6, 24.0, 7.0, 11.0, 81.0, 34.0, 1025.3, 1022.5, 5.0, 10.0, 1.0, 0.0]), rawPrediction=DenseVector([43617.0, 3814.0]), probability=DenseVector([0.9196, 0.0804]), prediction=0.0),\n",
       " Row(MinTemp=-3.0, MaxTemp=16.1, Rainfall=2.3499740743107256, WindGustSpeed=22.0, WindSpeed9am=0.0, WindSpeed3pm=0.0, Humidity9am=84.0, Humidity3pm=39.0, Pressure9am=1021.0, Pressure3pm=1018.8, WindGustDir_index=9.0, WindDir9am_index=0.0, WindDir3pm_index=0.0, RainToday_index=0.0, RainTomorrow_index=0.0, feature_vector=DenseVector([-3.0, 16.1, 2.35, 22.0, 0.0, 0.0, 84.0, 39.0, 1021.0, 1018.8, 9.0, 0.0, 0.0, 0.0]), rawPrediction=DenseVector([43617.0, 3814.0]), probability=DenseVector([0.9196, 0.0804]), prediction=0.0)]"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT_Prediction.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting predictions, let's evaluate the performance of our model using the `MulticlassClassificationEvaluator()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_Evaluator = MulticlassClassificationEvaluator(labelCol =  'RainTomorrow_index', predictionCol = 'prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_Accuracy = DT_Evaluator.evaluate(DT_Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy is : 81.61852942022482\n",
      "Test Error is : 0.18381470579775183\n"
     ]
    }
   ],
   "source": [
    "print('Decision Tree Accuracy is : ' + str(DT_Accuracy * 100))\n",
    "print('Test Error is : ' + str(1 - DT_Accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a bad prediction and error rate for a start! Next we have Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n",
    "We shall now build Random Forest. Using the `RandomForestClassifier()` and `.fit()` method on our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_Classifier = RandomForestClassifier(labelCol = 'RainTomorrow_index', featuresCol = 'feature_vector',  maxDepth = 5,\n",
    "    maxBins = 32, numTrees = 500)\n",
    "\n",
    "RF_Model = RF_Classifier.fit(rain_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the `.transform()` on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_Prediction = RF_Model.transform(rain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(MinTemp=-3.3, MaxTemp=22.2, Rainfall=0.0, WindGustSpeed=30.0, WindSpeed9am=0.0, WindSpeed3pm=13.0, Humidity9am=90.0, Humidity3pm=24.0, Pressure9am=1021.7, Pressure3pm=1016.2, WindGustDir_index=0.0, WindDir9am_index=0.0, WindDir3pm_index=7.0, RainToday_index=0.0, RainTomorrow_index=0.0, feature_vector=DenseVector([-3.3, 22.2, 0.0, 30.0, 0.0, 13.0, 90.0, 24.0, 1021.7, 1016.2, 0.0, 0.0, 7.0, 0.0]), rawPrediction=DenseVector([440.2649, 59.7351]), probability=DenseVector([0.8805, 0.1195]), prediction=0.0),\n",
       " Row(MinTemp=-3.1, MaxTemp=12.4, Rainfall=0.0, WindGustSpeed=13.0, WindSpeed9am=6.0, WindSpeed3pm=2.0, Humidity9am=69.0, Humidity3pm=60.0, Pressure9am=1029.2, Pressure3pm=1027.3, WindGustDir_index=13.0, WindDir9am_index=12.0, WindDir3pm_index=3.0, RainToday_index=0.0, RainTomorrow_index=0.0, feature_vector=DenseVector([-3.1, 12.4, 0.0, 13.0, 6.0, 2.0, 69.0, 60.0, 1029.2, 1027.3, 13.0, 12.0, 3.0, 0.0]), rawPrediction=DenseVector([440.203, 59.797]), probability=DenseVector([0.8804, 0.1196]), prediction=0.0),\n",
       " Row(MinTemp=-3.0, MaxTemp=13.3, Rainfall=0.0, WindGustSpeed=26.0, WindSpeed9am=7.0, WindSpeed3pm=13.0, Humidity9am=74.0, Humidity3pm=46.0, Pressure9am=1035.2, Pressure3pm=1032.6, WindGustDir_index=7.0, WindDir9am_index=10.0, WindDir3pm_index=4.0, RainToday_index=0.0, RainTomorrow_index=0.0, feature_vector=DenseVector([-3.0, 13.3, 0.0, 26.0, 7.0, 13.0, 74.0, 46.0, 1035.2, 1032.6, 7.0, 10.0, 4.0, 0.0]), rawPrediction=DenseVector([445.2914, 54.7086]), probability=DenseVector([0.8906, 0.1094]), prediction=0.0),\n",
       " Row(MinTemp=-3.0, MaxTemp=15.4, Rainfall=0.6, WindGustSpeed=24.0, WindSpeed9am=7.0, WindSpeed3pm=11.0, Humidity9am=81.0, Humidity3pm=34.0, Pressure9am=1025.3, Pressure3pm=1022.5, WindGustDir_index=5.0, WindDir9am_index=10.0, WindDir3pm_index=1.0, RainToday_index=0.0, RainTomorrow_index=0.0, feature_vector=DenseVector([-3.0, 15.4, 0.6, 24.0, 7.0, 11.0, 81.0, 34.0, 1025.3, 1022.5, 5.0, 10.0, 1.0, 0.0]), rawPrediction=DenseVector([426.6086, 73.3914]), probability=DenseVector([0.8532, 0.1468]), prediction=0.0),\n",
       " Row(MinTemp=-3.0, MaxTemp=16.1, Rainfall=2.3499740743107256, WindGustSpeed=22.0, WindSpeed9am=0.0, WindSpeed3pm=0.0, Humidity9am=84.0, Humidity3pm=39.0, Pressure9am=1021.0, Pressure3pm=1018.8, WindGustDir_index=9.0, WindDir9am_index=0.0, WindDir3pm_index=0.0, RainToday_index=0.0, RainTomorrow_index=0.0, feature_vector=DenseVector([-3.0, 16.1, 2.35, 22.0, 0.0, 0.0, 84.0, 39.0, 1021.0, 1018.8, 9.0, 0.0, 0.0, 0.0]), rawPrediction=DenseVector([403.975, 96.025]), probability=DenseVector([0.8079, 0.1921]), prediction=0.0)]"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_Prediction.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting predictions, let's evaluate the performance of our model using the `MulticlassClassificationEvaluator()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_Evaluator = MulticlassClassificationEvaluator(labelCol = 'RainTomorrow_index', predictionCol = 'prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_Accuracy = RF_Evaluator.evaluate(RF_Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy is : 81.27162310981645\n",
      "Test Error is : 0.1872837689018355\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest Accuracy is : ' + str(RF_Accuracy * 100))\n",
    "print('Test Error is : ' + str(1 - RF_Accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm. More or less the same perfomance as Decision Tree's. In that case, we would prefer Decision Trees over Random Forest becasue it's **faster** and **more interpretable**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosted Tree\n",
    "\n",
    "We shall now build Gradient Boosted Machines. Using the `GBTClassifier()` and `.fit()` method on our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBT_Classifier = GBTClassifier(labelCol = 'RainTomorrow_index', featuresCol = 'feature_vector', maxIter = 20, maxDepth = 5, \n",
    "                               maxBins = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBT_Model = GBT_Classifier.fit(rain_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the `.transform()` on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBT_Prediction = GBT_Model.transform(rain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(MinTemp=-3.3, MaxTemp=22.2, Rainfall=0.0, WindGustSpeed=30.0, WindSpeed9am=0.0, WindSpeed3pm=13.0, Humidity9am=90.0, Humidity3pm=24.0, Pressure9am=1021.7, Pressure3pm=1016.2, WindGustDir_index=0.0, WindDir9am_index=0.0, WindDir3pm_index=7.0, RainToday_index=0.0, RainTomorrow_index=0.0, feature_vector=DenseVector([-3.3, 22.2, 0.0, 30.0, 0.0, 13.0, 90.0, 24.0, 1021.7, 1016.2, 0.0, 0.0, 7.0, 0.0]), rawPrediction=DenseVector([1.3648, -1.3648]), probability=DenseVector([0.9388, 0.0612]), prediction=0.0),\n",
       " Row(MinTemp=-3.1, MaxTemp=12.4, Rainfall=0.0, WindGustSpeed=13.0, WindSpeed9am=6.0, WindSpeed3pm=2.0, Humidity9am=69.0, Humidity3pm=60.0, Pressure9am=1029.2, Pressure3pm=1027.3, WindGustDir_index=13.0, WindDir9am_index=12.0, WindDir3pm_index=3.0, RainToday_index=0.0, RainTomorrow_index=0.0, feature_vector=DenseVector([-3.1, 12.4, 0.0, 13.0, 6.0, 2.0, 69.0, 60.0, 1029.2, 1027.3, 13.0, 12.0, 3.0, 0.0]), rawPrediction=DenseVector([1.1724, -1.1724]), probability=DenseVector([0.9125, 0.0875]), prediction=0.0),\n",
       " Row(MinTemp=-3.0, MaxTemp=13.3, Rainfall=0.0, WindGustSpeed=26.0, WindSpeed9am=7.0, WindSpeed3pm=13.0, Humidity9am=74.0, Humidity3pm=46.0, Pressure9am=1035.2, Pressure3pm=1032.6, WindGustDir_index=7.0, WindDir9am_index=10.0, WindDir3pm_index=4.0, RainToday_index=0.0, RainTomorrow_index=0.0, feature_vector=DenseVector([-3.0, 13.3, 0.0, 26.0, 7.0, 13.0, 74.0, 46.0, 1035.2, 1032.6, 7.0, 10.0, 4.0, 0.0]), rawPrediction=DenseVector([1.3766, -1.3766]), probability=DenseVector([0.9401, 0.0599]), prediction=0.0),\n",
       " Row(MinTemp=-3.0, MaxTemp=15.4, Rainfall=0.6, WindGustSpeed=24.0, WindSpeed9am=7.0, WindSpeed3pm=11.0, Humidity9am=81.0, Humidity3pm=34.0, Pressure9am=1025.3, Pressure3pm=1022.5, WindGustDir_index=5.0, WindDir9am_index=10.0, WindDir3pm_index=1.0, RainToday_index=0.0, RainTomorrow_index=0.0, feature_vector=DenseVector([-3.0, 15.4, 0.6, 24.0, 7.0, 11.0, 81.0, 34.0, 1025.3, 1022.5, 5.0, 10.0, 1.0, 0.0]), rawPrediction=DenseVector([1.3935, -1.3935]), probability=DenseVector([0.942, 0.058]), prediction=0.0),\n",
       " Row(MinTemp=-3.0, MaxTemp=16.1, Rainfall=2.3499740743107256, WindGustSpeed=22.0, WindSpeed9am=0.0, WindSpeed3pm=0.0, Humidity9am=84.0, Humidity3pm=39.0, Pressure9am=1021.0, Pressure3pm=1018.8, WindGustDir_index=9.0, WindDir9am_index=0.0, WindDir3pm_index=0.0, RainToday_index=0.0, RainTomorrow_index=0.0, feature_vector=DenseVector([-3.0, 16.1, 2.35, 22.0, 0.0, 0.0, 84.0, 39.0, 1021.0, 1018.8, 9.0, 0.0, 0.0, 0.0]), rawPrediction=DenseVector([0.8503, -0.8503]), probability=DenseVector([0.8456, 0.1544]), prediction=0.0)]"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBT_Prediction.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting predictions, let's evaluate the performance of our model using the `MulticlassClassificationEvaluator()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBT_Evaluator = MulticlassClassificationEvaluator(labelCol = 'RainTomorrow_index', predictionCol = 'prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBT_Accuracy = GBT_Evaluator.evaluate(GBT_Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBT Accuracy is : 82.90374067314038\n",
      "Test Error is : 0.1709625932685962\n"
     ]
    }
   ],
   "source": [
    "print('GBT Accuracy is : ' + str(GBT_Accuracy * 100))\n",
    "print('Test Error is : ' + str(1 - GBT_Accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better performance than both Decision Trees and Random Forest! But sadly, not by much. Onwards we go to our last algorithm, Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "We shall now build Logistic Regression model. Using the `LogisticRegression()` and `.fit()` method on our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogReg_Classifier = LogisticRegression(regParam = 0.3, labelCol = \"RainTomorrow_index\", featuresCol = 'feature_vector', \\\n",
    "                                       maxIter = 20,  elasticNetParam = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogReg_Model = LogReg_Classifier.fit(rain_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the `.transform()` on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(MinTemp=-3.3, MaxTemp=22.2, Rainfall=0.0, WindGustSpeed=30.0, WindSpeed9am=0.0, WindSpeed3pm=13.0, Humidity9am=90.0, Humidity3pm=24.0, Pressure9am=1021.7, Pressure3pm=1016.2, WindGustDir_index=0.0, WindDir9am_index=0.0, WindDir3pm_index=7.0, RainToday_index=0.0, RainTomorrow_index=0.0, feature_vector=DenseVector([-3.3, 22.2, 0.0, 30.0, 0.0, 13.0, 90.0, 24.0, 1021.7, 1016.2, 0.0, 0.0, 7.0, 0.0]), rawPrediction=DenseVector([1.2414, -1.2414]), probability=DenseVector([0.7758, 0.2242]), prediction=0.0),\n",
       " Row(MinTemp=-3.1, MaxTemp=12.4, Rainfall=0.0, WindGustSpeed=13.0, WindSpeed9am=6.0, WindSpeed3pm=2.0, Humidity9am=69.0, Humidity3pm=60.0, Pressure9am=1029.2, Pressure3pm=1027.3, WindGustDir_index=13.0, WindDir9am_index=12.0, WindDir3pm_index=3.0, RainToday_index=0.0, RainTomorrow_index=0.0, feature_vector=DenseVector([-3.1, 12.4, 0.0, 13.0, 6.0, 2.0, 69.0, 60.0, 1029.2, 1027.3, 13.0, 12.0, 3.0, 0.0]), rawPrediction=DenseVector([1.2414, -1.2414]), probability=DenseVector([0.7758, 0.2242]), prediction=0.0),\n",
       " Row(MinTemp=-3.0, MaxTemp=13.3, Rainfall=0.0, WindGustSpeed=26.0, WindSpeed9am=7.0, WindSpeed3pm=13.0, Humidity9am=74.0, Humidity3pm=46.0, Pressure9am=1035.2, Pressure3pm=1032.6, WindGustDir_index=7.0, WindDir9am_index=10.0, WindDir3pm_index=4.0, RainToday_index=0.0, RainTomorrow_index=0.0, feature_vector=DenseVector([-3.0, 13.3, 0.0, 26.0, 7.0, 13.0, 74.0, 46.0, 1035.2, 1032.6, 7.0, 10.0, 4.0, 0.0]), rawPrediction=DenseVector([1.2414, -1.2414]), probability=DenseVector([0.7758, 0.2242]), prediction=0.0),\n",
       " Row(MinTemp=-3.0, MaxTemp=15.4, Rainfall=0.6, WindGustSpeed=24.0, WindSpeed9am=7.0, WindSpeed3pm=11.0, Humidity9am=81.0, Humidity3pm=34.0, Pressure9am=1025.3, Pressure3pm=1022.5, WindGustDir_index=5.0, WindDir9am_index=10.0, WindDir3pm_index=1.0, RainToday_index=0.0, RainTomorrow_index=0.0, feature_vector=DenseVector([-3.0, 15.4, 0.6, 24.0, 7.0, 11.0, 81.0, 34.0, 1025.3, 1022.5, 5.0, 10.0, 1.0, 0.0]), rawPrediction=DenseVector([1.2414, -1.2414]), probability=DenseVector([0.7758, 0.2242]), prediction=0.0),\n",
       " Row(MinTemp=-3.0, MaxTemp=16.1, Rainfall=2.3499740743107256, WindGustSpeed=22.0, WindSpeed9am=0.0, WindSpeed3pm=0.0, Humidity9am=84.0, Humidity3pm=39.0, Pressure9am=1021.0, Pressure3pm=1018.8, WindGustDir_index=9.0, WindDir9am_index=0.0, WindDir3pm_index=0.0, RainToday_index=0.0, RainTomorrow_index=0.0, feature_vector=DenseVector([-3.0, 16.1, 2.35, 22.0, 0.0, 0.0, 84.0, 39.0, 1021.0, 1018.8, 9.0, 0.0, 0.0, 0.0]), rawPrediction=DenseVector([1.2414, -1.2414]), probability=DenseVector([0.7758, 0.2242]), prediction=0.0)]"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogReg_Prediction = LogReg_Model.transform(rain_test)\n",
    "\n",
    "LogReg_Prediction.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting predictions, let's evaluate the performance of our model using the `MulticlassClassificationEvaluator()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogReg_Evaluator = MulticlassClassificationEvaluator(labelCol = \"RainTomorrow_index\", predictionCol = \"prediction\", \\\n",
    "                                                     metricName = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogReg_Accuracy = LogReg_Evaluator.evaluate(LogReg_Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy is : 77.58288223404503\n",
      "Test Error is : 0.22417117765954975\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression Accuracy is : ' + str(LogReg_Accuracy * 100))\n",
    "print('Test Error is : ' + str(1 - LogReg_Accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression seems to be doing just okay as compared to our other algorithms. Let's get into more model performace indicators like Confusion Matrix, Recall, Precision, F1 Score etc.\n",
    "\n",
    "Now, let's get a sense of all prediction accuracies by visualizing them. We could perhaps, use a bar chart for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a59ebfe710>"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc = {'figure.figsize':(15, 12)})\n",
    "\n",
    "model_classifiers = ['Gradient Boosting Trees', 'Decision Trees', 'Random Forest', 'Logistic Regression']\n",
    "\n",
    "model_accuracies = [GBT_Accuracy * 100, DT_Accuracy * 100, RF_Accuracy * 100, LogReg_Accuracy * 100]\n",
    "\n",
    "sns.barplot(y = model_classifiers, x = model_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 09: Calculate the confusion matrix and find the precision, recall, and F1 score of each classification algorithm. Explain how the accuracy of the predication can be improved? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBT Model Performance\n",
    "\n",
    "For this task, we must make a **Confusion Matrix**, find the **Precision, Recall and F1-Score** for all the algorithms.\n",
    "\n",
    "We will be making use of built-in functions such as `MulticlassMetrics()`, `confusionMatrix()` for this task. For the other metrics like Precision, Recall and F1-Score, we can calculate them by **manipulating the confusion matrix**.\n",
    "\n",
    "As we will repeat the same for everything, there's no need to repeat the documentation for everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBT_Prediction_Labels = GBT_Prediction.select(['prediction', 'RainTomorrow_index'])\n",
    "\n",
    "GBT_KPI = MulticlassMetrics(GBT_Prediction_Labels.rdd.map(list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBT Confusion Matrix\n",
      "[[31788.  1606.]\n",
      " [ 5160.  4489.]]\n"
     ]
    }
   ],
   "source": [
    "GBT_confusion_matrix = GBT_KPI.confusionMatrix().toArray()\n",
    "\n",
    "print('GBT Confusion Matrix')\n",
    "\n",
    "print(GBT_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBT Precision = 0.8603442676193569\n"
     ]
    }
   ],
   "source": [
    "GBT_precision = (GBT_confusion_matrix[0][0]) / (GBT_confusion_matrix[0][0] + GBT_confusion_matrix[1][0])\n",
    "print('GBT Precision = ' + str(GBT_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBT Recall = 0.9519075282984968\n"
     ]
    }
   ],
   "source": [
    "GBT_recall = (GBT_confusion_matrix[0][0]) / (GBT_confusion_matrix[0][0] + GBT_confusion_matrix[0][1])\n",
    "print('GBT Recall = ' + str(GBT_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBT F1 Score = 0.9038128003184441\n"
     ]
    }
   ],
   "source": [
    "GBT_f1Score = (GBT_precision * GBT_recall) / (GBT_precision + GBT_recall) * 2\n",
    "print('GBT F1 Score = ' + str(GBT_f1Score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_Prediction_Labels = DT_Prediction.select(['prediction', 'RainTomorrow_index'])\n",
    "\n",
    "DT_KPI = MulticlassMetrics(DT_Prediction_Labels.rdd.map(list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Confusion Matrix\n",
      "[[32153.  1241.]\n",
      " [ 5805.  3844.]]\n"
     ]
    }
   ],
   "source": [
    "DT_confusion_matrix = DT_KPI.confusionMatrix().toArray()\n",
    "\n",
    "print('DT Confusion Matrix')\n",
    "\n",
    "print(DT_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Precision = 0.8470678117919807\n"
     ]
    }
   ],
   "source": [
    "DT_precision = (DT_confusion_matrix[0][0]) / (DT_confusion_matrix[0][0] + DT_confusion_matrix[1][0])\n",
    "print('DT Precision = ' + str(DT_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Recall = 0.9628376355033839\n"
     ]
    }
   ],
   "source": [
    "DT_recall = (DT_confusion_matrix[0][0]) / (DT_confusion_matrix[0][0] + DT_confusion_matrix[0][1])\n",
    "print('DT Recall = ' + str(DT_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT F1 Score = 0.9012501401502411\n"
     ]
    }
   ],
   "source": [
    "DT_f1Score = (DT_precision * DT_recall) / (DT_precision + DT_recall) * 2\n",
    "print('DT F1 Score = ' + str(DT_f1Score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_Prediction_Labels = RF_Prediction.select(['prediction', 'RainTomorrow_index'])\n",
    "\n",
    "RF_KPI = MulticlassMetrics(RF_Prediction_Labels.rdd.map(list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Confusion Matrix\n",
      "[[32309.  1085.]\n",
      " [ 6006.  3643.]]\n"
     ]
    }
   ],
   "source": [
    "RF_confusion_matrix = RF_KPI.confusionMatrix().toArray()\n",
    "\n",
    "print('RF Confusion Matrix')\n",
    "\n",
    "print(RF_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Precision = 0.8432467701944408\n"
     ]
    }
   ],
   "source": [
    "RF_precision = (RF_confusion_matrix[0][0]) / (RF_confusion_matrix[0][0] + RF_confusion_matrix[1][0])\n",
    "print('RF Precision = ' + str(RF_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Recall = 0.9675091333772534\n"
     ]
    }
   ],
   "source": [
    "RF_recall = (RF_confusion_matrix[0][0]) / (RF_confusion_matrix[0][0] + RF_confusion_matrix[0][1])\n",
    "print('RF Recall = ' + str(RF_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF F1 Score = 0.9011142255504888\n"
     ]
    }
   ],
   "source": [
    "RF_f1Score = (RF_precision * RF_recall) / (RF_precision + RF_recall) * 2\n",
    "print('RF F1 Score = ' + str(RF_f1Score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogReg_Prediction_Labels = LogReg_Prediction.select(['prediction', 'RainTomorrow_index'])\n",
    "\n",
    "LogReg_KPI = MulticlassMetrics(LogReg_Prediction_Labels.rdd.map(list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg Confusion Matrix\n",
      "[[33394.     0.]\n",
      " [ 9649.     0.]]\n"
     ]
    }
   ],
   "source": [
    "LogReg_confusion_matrix = LogReg_KPI.confusionMatrix().toArray()\n",
    "\n",
    "print('LogReg Confusion Matrix')\n",
    "\n",
    "print(LogReg_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg Precision = 0.7758288223404503\n"
     ]
    }
   ],
   "source": [
    "LogReg_precision = (LogReg_confusion_matrix[0][0]) / (LogReg_confusion_matrix[0][0] + LogReg_confusion_matrix[1][0])\n",
    "print('LogReg Precision = ' + str(LogReg_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg Recall = 1.0\n"
     ]
    }
   ],
   "source": [
    "LogReg_recall = (LogReg_confusion_matrix[0][0]) / (LogReg_confusion_matrix[0][0] + LogReg_confusion_matrix[0][1])\n",
    "print('LogReg Recall = ' + str(LogReg_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg F1 Score = 0.8737653230765206\n"
     ]
    }
   ],
   "source": [
    "LogReg_f1Score = (LogReg_precision * LogReg_recall) / (LogReg_precision + LogReg_recall) * 2\n",
    "print('LogReg F1 Score = ' + str(LogReg_f1Score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How can we Improve the Accuracy?\n",
    "\n",
    "We know that there isn't a single Machine Learning Algorithm that makes the best prediction on all problems. For example, SVM (Support Vector Machine) might do an okay job at **Regression** problems, but it does amazingly well at **Text Classification** problems. This is known as the **No Free Lunch** theorem. Therefore, we can only do trial and error with different algorithms unti we encounter the best algorithm for the problem.\n",
    "\n",
    "There are two other ways which come to mind when we think about increasing the accuracy of the model :\n",
    "\n",
    "1) **Hyperparameter Tuning** - This refers to finding the best set of parameters for any given problem, by tweeking and changing it and observing accuracy against it. We can automate this by using **grid search**, which basically makes use of a wide range of parameters for tweeking until the best set of parameters is found!\n",
    "\n",
    "2) **Tackling Highly Imbalanced Data** - In this problem of predicting the RainTomorrow label, the initial proportion of Yes:No in the training set is about 1:4 which is highly imbalanced as the **Yes** class label is far less represented than the class **No** label. This can influence the prediction probability in our final model. This can be dealt with methods like **Prior Probability, Weighted Matrix** methods etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "StringIndexer - https://stackoverflow.com/questions/36942233/apply-stringindexer-to-several-columns-in-a-pyspark-dataframe\n",
    "\n",
    "VectorAssembler - https://stackoverflow.com/questions/32606294/create-feature-vector-programmatically-in-spark-ml-pyspark\n",
    "\n",
    "Spark ML Guide - https://spark.apache.org/docs/latest/api/python/index.html\n",
    "\n",
    "Seaborn - https://seaborn.pydata.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
